{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from IPython import display\n",
    "import time\n",
    "from io import BytesIO\n",
    "import ipywidgets as widgets\n",
    "import cv2\n",
    "print(\"Opencv version: \"+cv2.__version__)\n",
    "import torch\n",
    "print(\"Torch version: \"+torch.__version__)\n",
    "#import torchvision\n",
    "#print(\"Torchvision version: \"+torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, filename = (\"https://upload.wikimedia.org/wikipedia/commons/f/f6/View_of_Valdivia_from_Pedro_de_Valdivia_bridge.jpg\", \"asd.jpg\")\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "img = Image.open('asd.jpg')\n",
    "!rm asd.jpg\n",
    "display.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de imágenes digitales\n",
    "\n",
    "Una imagen está compuesta de píxeles\n",
    "\n",
    "Cada píxel nos da información de color en una cierto lugar de la imagen\n",
    "\n",
    "El color está codificado como tres números: RGB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "data = np.array(img)[200:300, 50:250, :]\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 2), tight_layout=True)\n",
    "for k in range(3):\n",
    "    b = np.zeros((3, ))\n",
    "    b[k] = 1\n",
    "    custom_cmap = LinearSegmentedColormap.from_list('custom_cmap', [(0, 0, 0), b], N=100)\n",
    "    ax[k].imshow(data[:, :, k], cmap=custom_cmap)\n",
    "    ax[k].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bw = 0.2989*data[:, :, 0] + 0.587*data[:, :, 1]+ 0.114*data[:, :, 2]\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(9, 2), tight_layout=True)\n",
    "ax.imshow(img_bw, cmap=plt.cm.Greys_r)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los computadores ven las imagenes como arreglos de números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos operar estos arreglos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "filt = np.zeros(shape=(D, D))\n",
    "filt[1:-1, 1:-1] = 1\n",
    "display(filt)\n",
    "img_res = scipy.signal.correlate2d(data.astype('float32'), filt/np.sum(filt), mode='valid')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3), tight_layout=True)\n",
    "ax[0].imshow(subimg, cmap=plt.cm.Greys_r)\n",
    "ax[1].imshow(filt, cmap=plt.cm.Greys_r)\n",
    "ax[2].imshow(img_res, cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localización y clasificación de entidades en una imagen\n",
    "\n",
    "Descargamos una imagen \"cualquiera\" de internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, filename = (\"http://4.bp.blogspot.com/_PED_9yjYLVs/S6-fsdvtV9I/AAAAAAAAAGY/3py429MtnQ4/s1600/perros+vagos.jpg\", \"dogs.jpg\")\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "img = Image.open('dogs.jpg')\n",
    "!rm dogs.jpg\n",
    "display.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos un modelo Faster RCNN implementado en pytorch y entrenado en el dataset [COCO](https://github.com/nightrome/cocostuff/blob/master/labels.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2name = {1: 'persona', 2: 'bicicleta', 3: 'auto', 4: 'moto', \n",
    "              8: 'camioneta', 18: 'perro'}\n",
    "\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "# Descargo un modelo detector pre-entrenado\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval();\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo retorna \n",
    "- las coordenadas de la detección (bounding box)\n",
    "- la etiqueta (label) de la detección\n",
    "- la probabilidad de la detección "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "img_tensor = transform(img)\n",
    "img_tensor = img_tensor.to('cuda:0')\n",
    "result = model(img_tensor.unsqueeze(0))[0]\n",
    "\n",
    "def filter_results(result, threshold=0.9):\n",
    "    mask = result['scores'] > 0.9\n",
    "    bbox = result['boxes'][mask].detach().cpu().numpy()\n",
    "    lbls = result['labels'][mask].detach().cpu().numpy()\n",
    "    return bbox, lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnt = ImageFont.truetype(\"arial.ttf\", 30) \n",
    "\n",
    "def draw_rectangles(img, bbox, lbls):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for k in range(len(bbox)):\n",
    "        if lbls[k] in label2name.keys():\n",
    "            draw.rectangle(bbox[k], fill=None, outline='white', width=4)\n",
    "            draw.text([int(d) for d in bbox[k][:2]], label2name[lbls[k]], font=fnt, fill='white')\n",
    "\n",
    "bbox, lbls = filter_results(result)\n",
    "draw_rectangles(img, bbox, lbls)\n",
    "display.display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localización y clasificación de entidades en un video\n",
    "\n",
    "Podemos realizar el mismo procedimiento en cada uno de los cuadros de un video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnt = ImageFont.truetype(\"arial.ttf\", 40) \n",
    "out = widgets.Output(layout=widgets.Layout(height='480px', width = '720px', border='none'))\n",
    "display.display(out)            \n",
    "vid = cv2.VideoCapture('valdivia.mp4')\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        for k in range(2): # drop one frame\n",
    "            ret, frame = vid.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        torch_frame = transform(frame)\n",
    "        torch_frame = torch_frame.to('cuda:0')\n",
    "        result = model(torch_frame.unsqueeze(0))[0]\n",
    "        bbox, lbls = filter_results(result, threshold=0.1)\n",
    "        img = Image.fromarray(frame)\n",
    "        draw_rectangles(img, bbox, lbls)\n",
    "        with out:       \n",
    "            buffer = BytesIO() \n",
    "            img.save(buffer, format='JPEG')\n",
    "            display.display(display.Image(data=buffer.getvalue()))\n",
    "            display.clear_output(wait=True)\n",
    "        #time.sleep(0.1)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    vid.release()\n",
    "#https://github.com/NicksonYap/Jupyter-Webcam/blob/master/Realtime_video_ipython_py3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Redes Neuronales](https://docs.google.com/presentation/d/16lErEZ2VBt8a-K4lrgdmvaaTOma5sDXvW5fUbLS6qWE/edit#slide=id.g33ee194b7d_0_889)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://thispersondoesnotexist.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
